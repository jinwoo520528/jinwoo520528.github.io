<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Jinwoo Park</title>
    <meta name="author" content="Jinwoo Park" />
    <meta name="description" content="About Jinwoo Park.
" />
    <meta name="keywords" content="cv, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/al-folio/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="assets/js/theme.js"></script>
    <script src="assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="https://jinwoo520528.github.io/">about<span class="sr-only">(current)</span></a>
              </li>
              
              <li class="nav-item ">
                <a class="nav-link" href="https://drive.google.com/file/d/1xVV2cXwG1VGN9QjXHiXN32DZlSPFzARy/view?usp=sharing" target="_blank">cv</a>
              </li>

              <!-- Blog -->
              <!--li class="nav-item ">
                <a class="nav-link" href="/">blog</a>
              </li-->

              
              <!-- Other pages -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/al-folio/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/al-folio/publications/">publications</a>
              </li> -->
              <!-- <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/al-folio/publications/">publications</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/al-folio/projects/">projects</a>
                </div>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/al-folio/teaching/">teaching</a>
              </li> -->

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <span class="font-weight-bold">Youngmok</span> Jung
          </h1>
          <p class="desc"> jinwoo520528@kaist.ac.kr | <a href="https://scholar.google.com/citations?user=C-4x6scAAAAJ&hl=en" target="_blank">Google Scholar</a> | <a href="https://www.linkedin.com/in/jinwoo520528/" target="_blank">Linkedin</a> | <a href="https://drive.google.com/file/d/1xVV2cXwG1VGN9QjXHiXN32DZlSPFzARy/view?usp=sharing" target="_blank">CV</a></p>
        </header>

        <article>
          <div class="profile float-right">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="assets/images/profile.jpg"></source>
    <source media="(max-width: 800px)" srcset="assets/images/profile.jpg"></source>
    <source media="(max-width: 1400px)" srcset="assets/images/profile.jpg"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded" src="assets/images/profile.jpg" alt="Jinwoo Park">

  </picture>

</figure>

            <div class="address">
              <!-- <p>555 your office number</p> <p>123 your address street</p> <p>Your City, State 12345</p> -->

            </div>
          </div>

          <div class="clearfix">
            <p>I am a computer science PhD candidate at <a href="https://ina.kaist.ac.kr/" target="_blank">INA lab</a>, KAIST advised by <a href="http://ina.kaist.ac.kr/~dongsuh/" target="_blank">Dongsu Han</a>. Before then, I received my MS degree in Electrical Engineering at KAIST, advised by <a href="https://yung-web.github.io/home/" target="_blank">Yi Yung</a>.</p>
              <!-- Link to your favorite <a href="http://reddit.com" target="_blank" rel="noopener noreferrer">subreddit</a>. You can put a picture in, too. The code is already in, just name your picture <code class="language-plaintext highlighter-rouge">prof_pic.jpg</code> and put it in the <code class="language-plaintext highlighter-rouge">img/</code> folder.</p> -->

        <!-- <code class="language-plaintext highlighter-rouge">profile</code> property of the YAML header of your <code class="language-plaintext highlighter-rouge">_pages/about.md</code>. Edit <code class="language-plaintext highlighter-rouge">_bibliography/papers.bib</code> and Jekyll will render your <a href="/al-folio/publications/">publications page</a> automatically.</p> -->

<p>
  My interests are in crafting systems that incorporate AI/ML approaches.
  I concentrate on utilizing underlying assumptions of real-world systems to enhance the integration of these AI/ML techniques.
  My works aims at 1) designing efficient system built on AI/ML approaches; 2) improving AI/ML approaches by exploiting system-specific assumptions. 
  All my work involves several months of implementation followed by thorough testing in real-world data.
  </p><p>Recently, I am striving to develop adaptive load control framework for microservices using AI/ML approaches. 
  In the past, I worked on various topics in applying reinforcement learning and image super-resolution based on neural network.</p>
           
          <!-- </div>

          News          
          <div class="news">
            <h2>Awards and Honors</h2>
            <div class="table-responsive">
              <table class="table table-sm table-borderless"> 
                <tr>
                  <th scope="row">Feb, 2023</th>
                  <td>
                    Samsung Electronics 29th Humantech Paper Award (Silver Prize, Communication & Networks) 
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb, 2022</th>
                  <td>
                    Samsung Electronics PhD Scholarship <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Spring, 2021</th>
                  <td>
                    <a class="news-title" href="http://breakthroughs.kaist.ac.kr/newsletter/2021/16/default.htm" target="_blank">KAIST Breakthrough of the Year 2021, Spring (LiveNAS, NEMO)</a> 
                  </td>
                </tr> 
                <!-- <tr>
                  <th scope="row">Oct 22, 2015</th>
                  <td>
                    A simple inline announcement.
                  </td>
                </tr>  -->
              </table>
            </div> 
          </div> -->

          <!-- Selected papers -->
          <div class="publications">
            <h2>Selected Publications</h2>
            <ol class="bibliography"><li>
            <!-- _layouts/bib.html -->
            <div class="row">
              <div class="col-sm-2 abbr"><abbr class="badge">Bioinformatics</abbr></div>
              <!-- Entry bib key -->
              <div id="PhysRev.47.777" class="col-sm-8">
                <!-- Title -->
                <div class="title">BWA-MEME: BWA-MEM emulated with a machine learning approach</div>
                <!-- Author -->
                <div class="author">
                        <!-- <em>Youngmok, Jung</em>, <a href="https://en.wikipedia.org/wiki/Boris_Podolsky" target="_blank" rel="noopener noreferrer">Podolsky, B.</a>, and <a href="https://en.wikipedia.org/wiki/Nathan_Rosen" target="_blank" rel="noopener noreferrer">Rosen, N.</a> -->
                        <em>Youngmok Jung</em> and Dongsu Han
                </div>
                <!-- Journal/Book title and date -->
                <div class="periodical">
                  <em>Oxford Bioinformatics,</em> 2022
                </div>
                <!-- Links/Buttons -->
                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btac137/6543607" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
                  <a href="https://github.com/kaist-ina/bwa-meme" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Github</a>
                  <!-- <a href="assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> -->
                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>The growing use of next-generation sequencing and enlarged sequencing throughput require efficient short-read alignment, where seeding is one of the major performance bottlenecks. The key challenge in the seeding phase is searching for exact matches of substrings of short reads in the reference DNA sequence. Existing algorithms, however, present limitations in performance due to their frequent memory accesses.</p>
                  <p>This paper presents BWA-MEME, the first full-fledged short read alignment software that leverages learned indices for solving the exact match search problem for efficient seeding. BWA-MEME is a practical and efficient seeding algorithm based on a suffix array search algorithm that solves the challenges in utilizing learned indices for SMEM search which is extensively used in the seeding phase. Our evaluation shows that BWA-MEME achieves up to 3.45x speedup in seeding throughput over BWA-MEM2 by reducing the number of instructions by 4.60x, memory accesses by 8.77x, and LLC misses by 2.21x, while ensuring the identical SAM output to BWA-MEM2.</p>
                </div>
              </div>
            </div>
            <!-- Row start -->
           
            <!-- Row start -->
            <div class="row">
              <div class="col-sm-2 abbr"><abbr class="badge">SIGCOMM</abbr></div>

              <!-- Entry bib key -->
              <div id="PhysRev.47.777" class="col-sm-8">
              
                <!-- Title -->
                <div class="title">LiveNAS - Neural-Enhanced Live Streaming: Improving Live Video Ingest via Online Learning</div>
                <!-- Author -->
                <div class="author">
                        <!-- <em>Youngmok, Jung</em>, <a href="https://en.wikipedia.org/wiki/Boris_Podolsky" target="_blank" rel="noopener noreferrer">Podolsky, B.</a>, and <a href="https://en.wikipedia.org/wiki/Nathan_Rosen" target="_blank" rel="noopener noreferrer">Rosen, N.</a> -->
                        Jaehong Kim, <em>(Co-first)Youngmok Jung</em>, Hyunho Yeo, Juncheol Ye and Dongsu Han
                </div>

                <!-- Journal/Book title and date -->
                <div class="periodical">
                  <em>In Proceedings of ACM SIGCOMM conference,</em> 2020
                </div>
              
                <!-- Links/Buttons -->
                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="http://ina.kaist.ac.kr/~livenas" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
                  <!-- <a href="assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> -->
                </div>

                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>Live video accounts for a significant volume of today’s Internet
                    video. Despite a large number of efforts to enhance user quality
                    of experience (QoE) both at the ingest and distribution side of live
                    video, the fundamental limitations are that streamer’s upstream
                    bandwidth and computational capacity limit the quality of experience of thousands of viewers.
                    To overcome this limitation, we design LiveNAS, a new live
                    video ingest framework that enhances the origin stream’s quality by leveraging computation at ingest servers. Our ingest server
                    applies neural super-resolution on the original stream, while imposing minimal overhead on ingest clients. LiveNAS employs online
                    learning to maximize the quality gain and dynamically adjusts the
                    resource use to the real-time quality improvement. LiveNAS delivers high-quality live streams up to 4K resolution, outperforming
                    WebRTC by 1.96 dB on average in Peak-Signal-to-Noise-Ratio on
                    real video streams and network traces, which leads to 12%-69% QoE
                    improvement for live stream viewers.</p>
                </div>
              </div>
            </div>
            <!-- Row start -->

          <div class="publications">
            <h2>Publications</h2>
            <ol class="bibliography"><li>

              <div class="row">

                  <div class="col-sm-2 abbr"><abbr class="badge">CoNEXT</abbr></div>
    
                  <!-- Entry bib key -->
                  <div id="PhysRev.47.777" class="col-sm-8">
                  
                    <!-- Title -->
                    <div class="title">Co-optimizing for Flow Completion Time in Radio Access Network</div>
                    <!-- Author -->
                    <div class="author">
                            Jaehong Kim, Yunheon Lee, Hwijoon Lim, <em>Youngmok Jung</em>, Song Min Kim, and Dongsu Han
                            
                    </div>
    
                    <!-- Journal/Book title and date -->
                    <div class="periodical">
                      <em> In Proceedings of the 18th International Conference on emerging Networking EXperiments and Technologies,</em> 2022
                    </div>
                  
                    <!-- Links/Buttons -->
                    <div class="links">
                      <a class="abstract btn btn-sm z-depth-0" role="button">ABS</a>
                      <a href="https://dl.acm.org/doi/abs/10.1145/3555050.3569122" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
                      <!-- <a href="https://github.com/kaist-ina/neuroscaler-public" class="btn btn-sm z-depth-0" role="button">GITHUB</a> -->
                    </div>
    
                    <!-- Hidden abstract block -->
                    <div class="abstract hidden">
                      <p>Traffic from interactive applications demanding low latency has become dominant in cellular networks. However, existing schedulers of cellular network base stations fall short in delivering low latency when prior information (i.e., dedicated Quality of Service (QoS)) is unavailable; they become service agnostic and perform towards maximizing the radio resource utilization or user fairness. We identify a new opportunity of providing a better latency for those latency-sensitive traffic flows by additionally taking the Flow Completion Time (FCT) into account in downlink scheduling at the base stations. However, the key challenges are 1) it can bring a severe cost in optimization metrics of the existing scheduler and 2) it should work without prior knowledge of the traffic. To this end, we present OutRAN, a practical flow scheduler designed for Radio Access Network that co-optimizes the FCT and optimization objectives of the cellular scheduler. The resulting system does not require prior information. Through simulation and over-the-air evaluation, we demonstrate that OutRAN outperforms the legacy LTE/5G schedulers in FCT, which leads to the reduction in webpage load time of Android phones.</p>
                    </div>
                  </div>
                </div>


              <div class="row">
                <div class="col-sm-2 abbr"><abbr class="badge">SIGCOMM</abbr></div>
                <div id="PhysRev.47.777" class="col-sm-8">
                
                  <!-- Title -->
                  <div class="title">NeuroScaler: Neural Video Enhancement at Scale</div>
                  <!-- Author -->
                  <div class="author">
                          <!-- <em>Youngmok, Jung</em>, <a href="https://en.wikipedia.org/wiki/Boris_Podolsky" target="_blank" rel="noopener noreferrer">Podolsky, B.</a>, and <a href="https://en.wikipedia.org/wiki/Nathan_Rosen" target="_blank" rel="noopener noreferrer">Rosen, N.</a> -->
                          Hyunho Yeo, Hwijoon Lim, Jaehong Kim, <em>Youngmok Jung</em>, Juncheol Ye, and Dongsu Han
                          
                  </div>
  
                  <!-- Journal/Book title and date -->
                  <div class="periodical">
                    <em>In Proceedings of ACM SIGCOMM conference,</em> 2022
                  </div>
                
                  <!-- Links/Buttons -->
                  <div class="links">
                    <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                    <a href="https://dl.acm.org/doi/10.1145/3544216.3544218" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
                    <a href="https://github.com/kaist-ina/neuroscaler-public" class="btn btn-sm z-depth-0" role="button">GITHUB</a>
                  </div>
  
                  <!-- Hidden abstract block -->
                  <div class="abstract hidden">
                    <p>High-definition live streaming has experienced tremendous growth. However, the video quality of live video is often limited by the streamer's uplink bandwidth. Recently, neural-enhanced live streaming has shown great promise in enhancing the video quality by running neural super-resolution at the ingest server. Despite its benefit, it is too expensive to be deployed at scale. To overcome the limitation, we present NeuroScaler, a framework that delivers efficient and scalable neural enhancement for live streams. First, to accelerate end-to-end neural enhancement, we propose novel algorithms that significantly reduce the overhead of video super-resolution, encoding, and GPU context switching. Second, to maximize the overall quality gain, we devise a resource scheduler that considers the unique characteristics of the neural-enhancing workload. Our evaluation on a public cloud shows NeuroScaler reduces the overall cost by 22.3× and 3.0--11.1× compared to the latest per-frame and selective neural-enhancing systems, respectively.</p>
                  </div>
                </div>
              </div>

            <!-- Row start -->
            <div class="row">
              <div class="col-sm-2 abbr"><abbr class="badge">EuroSys</abbr></div>

              <!-- Entry bib key -->
              <div id="PhysRev.47.777" class="col-sm-8">
              
                <!-- Title -->
                <div class="title">Towards Timeout-less Transport in Commodity Datacenter Networks</div>
                <!-- Author -->
                <div class="author">
                        <!-- <em>Youngmok, Jung</em>, <a href="https://en.wikipedia.org/wiki/Boris_Podolsky" target="_blank" rel="noopener noreferrer">Podolsky, B.</a>, and <a href="https://en.wikipedia.org/wiki/Nathan_Rosen" target="_blank" rel="noopener noreferrer">Rosen, N.</a> -->
                        Hwijoon Lim, Wei Bai, Yibo Zhu, <em>Youngmok Jung</em> and Dongsu Han
                        
                </div>

                <!-- Journal/Book title and date -->
                <div class="periodical">
                  <em>The 16th European Conference on Computer Systems,</em> 2021
                </div>
              
                <!-- Links/Buttons -->
                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="https://dl.acm.org/doi/10.1145/3447786.3456227" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
                  <a href="https://github.com/kaist-ina/ns3-tlt-tcp-public" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Github</a>
                  <!-- <a href="assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> -->
                </div>

                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>Despite recent advances in datacenter networks, timeouts caused by congestion packet losses still remain a major cause of high tail latency. Priority-based Flow Control (PFC) was introduced to make the network lossless, but its Head-of-Line blocking nature causes various performance and management problems. In this paper, we ask if it is possible to design a network that achieves (near) zero timeout only using commodity hardware in datacenters.
                    Our answer is TLT, an extension to existing transport designed to eliminate timeouts. We are inspired by the observation that only certain types of packet drops cause timeouts. Therefore, instead of blindly dropping (TCP) or not dropping packets at all (RoCEv2), TLT proactively drops some packets to ensure the delivery of more important ones, whose losses may cause timeouts. It classifies packets at the host and leverages color-aware thresholding, a feature widely supported by commodity switches, to proactively drop some less important packets. We implement TLT prototypes using VMA to test with real applications. Our testbed evaluation on Redis shows that TLT reduces 99%-ile FCT up to 91.7% on handling bursts of SET operations. In large-scale simulations, TLT augments diverse datacenter transports, from widely-used (TCP, DCTCP, DCQCN) to state-of-the-art (IRN and HPCC), by achieving up to 81% lower tail latency.</p>
                </div>
              </div>
            </div>
            <!-- Row start -->
            <div class="row">
              <div class="col-sm-2 abbr"><abbr class="badge">Mobicom</abbr></div>

              <!-- Entry bib key -->
              <div id="PhysRev.47.777" class="col-sm-8">
              
                <!-- Title -->
                <div class="title">NEMO: Enabling Neural-enhanced Video Streaming on Commodity Mobile Devices</div>
                <!-- Author -->
                <div class="author">
                        <!-- <em>Youngmok, Jung</em>, <a href="https://en.wikipedia.org/wiki/Boris_Podolsky" target="_blank" rel="noopener noreferrer">Podolsky, B.</a>, and <a href="https://en.wikipedia.org/wiki/Nathan_Rosen" target="_blank" rel="noopener noreferrer">Rosen, N.</a> -->
                        Hyunho Yeo, Chan Ju Chong, <em>Youngmok Jung</em>, Juncheol Ye and Dongsu Han
                        
                </div>

                <!-- Journal/Book title and date -->
                <div class="periodical">
                  <em>The 26th Annual International Conference on Mobile Computing and Networking,</em> 2020
                </div>
              
                <!-- Links/Buttons -->
                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="http://ina.kaist.ac.kr/~nemo/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
                  <a href="https://github.com/kaist-ina/nemo" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Github</a>
                  <!-- <a href="assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> -->
                </div>

                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>The demand for mobile video streaming has experienced tremendous growth over the last decade. However, existing methods of video delivery fall short of delivering high-quality video. Recent advances in neural super-resolution have opened up the possibility of enhancing video quality by leveraging client-side computation. Unfortunately, mobile devices cannot benefit from this because it is too expensive in computation and power-hungry.
                    To overcome the limitation, we present NEMO, a system that enables real-time video super-resolution on mobile devices. NEMO applies neural super-resolution to a few select frames and transfers the outputs to benefit the remaining frames. The frames to which super-resolution is applied are carefully chosen to maximize the overall quality gains. NEMO leverages fine-grained dependencies using information from the video codec and strives to provide guarantees in the quality degradation compared to per-frame super-resolution. Our evaluation using a full system implementation on Android shows NEMO improves the overall processing throughput by x11.5, reduces energy consumption by 88.6%, and maintains device temperatures at acceptable levels compared to per-frame super-resolution, while ensuring high video quality. Overall, this leads to a 31.2% improvement in quality of experience for mobile users.</p>
                </div>
              </div>
            </div>
            
            <!-- Row start -->
            <div class="row">
              <div class="col-sm-2 abbr"><abbr class="badge">OSDI</abbr></div>

              <!-- Entry bib key -->
              <div id="PhysRev.47.777" class="col-sm-8">
              
                <!-- Title -->
                <div class="title">Neural Adaptive Content-aware Internet Video Delivery</div>
                <!-- Author -->
                <div class="author">
                        <!-- <em>Youngmok, Jung</em>, <a href="https://en.wikipedia.org/wiki/Boris_Podolsky" target="_blank" rel="noopener noreferrer">Podolsky, B.</a>, and <a href="https://en.wikipedia.org/wiki/Nathan_Rosen" target="_blank" rel="noopener noreferrer">Rosen, N.</a> -->
                        Hyunho Yeo, <em>Youngmok Jung</em>, Jaehong Kim, Jinwoo Shin, and Dongsu Han
                        
                </div>

                <!-- Journal/Book title and date -->
                <div class="periodical">
                  <em>13th USENIX Symposium on Operating Systems Design and Implementation,</em> 2018
                </div>
              
                <!-- Links/Buttons -->
                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="http://ina.kaist.ac.kr/~nas" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
                  <a href="https://github.com/kaist-ina/NAS_public" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Github</a>
                  <!-- <a href="assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> -->
                </div>

                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>Internet video streaming has experienced tremendous growth over the last few decades. However, the quality of existing video delivery critically depends on the bandwidth resource. Consequently, user quality of experience (QoE) suffers inevitably when network conditions become unfavorable. We present a new video delivery framework that utilizes client computation and recent advances in deep neural networks (DNNs) to reduce the dependency for delivering high-quality video. The use of DNNs enables us to enhance the video quality independent to the available bandwidth. We design a practical system that addresses several challenges, such as client heterogeneity, interaction with bitrate adaptation, and DNN transfer, in enabling the idea. Our evaluation using 3G and broadband network traces shows the proposed system outperforms the current state of the art, enhancing the average QoE by 43.08% using the same bandwidth budget or saving 17.13% of bandwidth while providing the same user QoE.</p>
                </div>
              </div>
            </div>

            </li></ol>
          </div>
          <div class="publications">
            <h2>Experiences</h2>
            <ol class="bibliography"><li>
            <!-- _layouts/bib.html -->
            
            <div class="row">
              
              <!-- Entry bib key -->
              <div id="PhysRev.47.777" class="col-sm-12">
                <div class="title">AI & ML for System</div>
                <p>
                </p>
                <div class="author">
                        - Used <b>image Super-resolution</b> deep learning model to enhance the video streaming system. Various techniques (e.g. Online training, Data specialization) were used to build practical system (LiveNAS, NAS) </br>
                        - Developed integrated <a href="https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming" target="_blank">ABR algorithm</a> using <b>Reinforcement-learning (a3c)</b> that predicts the network bandwidth and optimize the user QoE in video streaming. (NAS) </br>
                        - Developed new <b>learned-index</b> model structure that adapts to imbalanced DNA dataset. (BWA-MEME) </br>

                </div>
                
                <div class="row"> </br></div>
                <div class="title">Enhancing networked systems </div>
                <!-- Author -->
                <p>
                </p>
                <div class="author">
                        - [SIGCOMM'20 LiveNAS] Developed neural-enhanced live video streaming system (LiveNAS) that delivers live video with the same quality as WebRTC <b>using only 45.9% bandwidth on average</b>. LiveNAS system is built on top of Google WebRTC. </br>
                        - [OSDI'18 NAS] Developed <a target="_blank" href="https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP">VoD (video-on-demand)</a> streaming simulation environment for RL model. Also, validated the RL model works well on the real world after training on the simulation environment. </br>
                        - [EuroSYS'21] Implemented network protocols (TLT, PFC) in <a target="_blank" href="https://www.nsnam.org/">NS-3 network simulator</a>. </br>
                </div>

                <div class="row"> </br></div>
                <div class="title">Enhancing genome analysis pipeline with AI and ML techniques</div>
                <!-- Author -->
                <p>
                </p>
                <div class="author">
                        - [Bioinformatics'22] Developed new <a target="_blank" href="https://en.wikibooks.org/wiki/Next_Generation_Sequencing_(NGS)/Alignment">short-read alignment</a> software (BWA-MEME) using <b>learned-index</b> that achieved up to <b>3.45x speedup</b> over state-of-the-art algorithm. </br>
                        - (In-progress) Improving accuracy of deep learning-based variant caller.
                </div>
                
                <!-- <div class="row"> </br></div>
                <div class="title">Cloud and Datacenter</div>
                <p>
                </p>
                <div class="author">
                        - Microservice overload control 
                </div> -->


                <!-- <div class="row"> </br></div>
                <div class="title">Managing</div>
                <p>
                </p>
                <div class="author">
                        - </br>
                        - </br>

                </div> -->
                <!-- Journal/Book title and date -->
                <!-- Links/Buttons -->
                <!-- <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btac137/6543607" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
                  <a href="https://github.com/kaist-ina/bwa-meme" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Github</a>
                </div>
                <div class="abstract hidden">
                  <p>The growing use of next-generation sequencing and enlarged sequencing throughput require efficient short-read alignment, where seeding is one of the major performance bottlenecks. The key challenge in the seeding phase is searching for exact matches of substrings of short reads in the reference DNA sequence. Existing algorithms, however, present limitations in performance due to their frequent memory accesses.</p>
                </div>
              </div> -->
              </div>
              </div>

<!-- 
              <div class="publications">
                <h2>Opensource</h2>
                <ol class="bibliography"></ol>
                <!-- _layouts/bib.html -->
                
                <div class="row">
                  
                  <!-- Entry bib key -->
                  <div id="PhysRev.47.777" class="col-sm-12">
                    <div class="title">BWA-MEME <img alt="badge" src="https://anaconda.org/bioconda/bwa-meme/badges/downloads.svg" data-airgap-id="25"></div>
                    <p><a target="_blank" href="https://github.com/kaist-ina/BWA-MEME">https://github.com/kaist-ina/BWA-MEME</a>  
                    
                  </br>
                    - Short-read alignment software, released for benefit of research community. 
                    </p>
                    <div class="author">
                    </div>
                    
                    <!--                     
                    <div class="title">TLT</div>
                    <p><a target="_blank" href="https://github.com/kaist-ina/ns3-tlt-tcp-public">https://github.com/kaist-ina/ns3-tlt-tcp-public</a>
                    </br>
                    - Repository for "Towards timeout-less transport in commodity datacenter networks"
                    </p>
                    <div class="author">
                    </div>
                    
                    <div class="title">NEMO</div>
                    <p><a target="_blank" href="https://github.com/kaist-ina/nemo">https://github.com/kaist-ina/nemo</a>
                    </br>
                    - Repository for "NEMO: Enabling Neural-enhanced Video Streaming on Commodity Mobile Devices"
                    </p>
                    <div class="author">
                    </div>

                    <div class="title">NAS</div>
                    <p><a target="_blank" href="https://github.com/kaist-ina/NAS_public">https://github.com/kaist-ina/NAS_public</a>
                    </br>
                    - Repository for "Neural Adaptive Content-aware Internet Video Delivery"
                    </p>
                    <div class="author">
                    </div> -->
                    
                  </div>
                </div>
              </div> -->
              
              <div class="publications">
                <h2>Skills</h2>
                <ol class="bibliography"></ol>
                <!-- _layouts/bib.html -->
                
                <div class="row">
                  
                  <!-- Entry bib key -->
                  <div id="PhysRev.47.777" class="col-sm-12">
                    <div class="title">Programming Languages: Python, C, C++, UNIX shell scripting</div>
                    <div class="title">Frameworks: Kubernetes, Pytorch, Tensorflow</div>
                    <p> 
                    </br>
                    </p>
                    <div class="author">
                    </div>
                    
                  </div>
                </div>
              </div>
          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <!-- <a href="mailto:jinwoo520528@kaist.ac.kr" title="email"><i class="fas fa-envelope"></i></a> -->
            <!-- <a href="http://localhost:4000/al-folio/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> -->
            
            </div>

            <div class="contact-note">
              <!-- Contact -->

            </div>
            
          </div>
        </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        <!-- © Copyright 2022 Youngmok Jung. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. -->

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="assets/js/common.js"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-DCDCK3RW8C"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DCDCK3RW8C');
</script>
    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
